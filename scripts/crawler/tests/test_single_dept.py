#!/usr/bin/env python3
"""
ë‹¨ì¼ í•™ê³¼ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…ìš©
"""

import sys
import os
import json

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from crawler.khu_crawler import KHUCrawler


def main():
    print("=" * 60)
    print("ğŸ§ª Single Department Crawling Test")
    print("=" * 60)
    print()

    # í•™ê³¼ ì½”ë“œ ì…ë ¥
    dept_code = input("Enter department code (e.g., A10627): ").strip()
    if not dept_code:
        print("âŒ No department code provided")
        return 1

    year = 2025
    semester = 1

    print(f"\nğŸ“‹ Parameters:")
    print(f"   Year: {year}")
    print(f"   Semester: {semester}")
    print(f"   Department: {dept_code}")
    print()

    crawler = KHUCrawler()

    try:
        print("ğŸ“¡ Fetching courses...")
        print("-" * 60)

        result = crawler.fetch_courses(
            year=year,
            semester=semester,
            major_code=dept_code
        )

        if not result:
            print("âŒ Failed to fetch data")
            return 1

        print()
        print("=" * 60)
        print("ğŸ“Š Result Summary")
        print("=" * 60)

        if 'rows' in result:
            courses = result['rows']
            print(f"âœ… Total courses: {len(courses)}")

            if len(courses) > 0:
                print("\nğŸ“ First course:")
                print(json.dumps(courses[0], indent=2, ensure_ascii=False))

                print("\nğŸ“ Field names:")
                for key in courses[0].keys():
                    print(f"   - {key}")

                # ê²°ê³¼ ì €ì¥
                output_file = f"output/test_{dept_code}_{year}_{semester}.json"
                os.makedirs('output', exist_ok=True)

                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(courses, f, ensure_ascii=False, indent=2)

                print(f"\nğŸ’¾ Saved to: {output_file}")
            else:
                print("âš ï¸  No courses found")
        else:
            print("âš ï¸  Unexpected response structure")
            print(f"Keys: {result.keys()}")

        return 0

    except Exception as e:
        print(f"\nâŒ Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

    finally:
        crawler.close()


if __name__ == "__main__":
    sys.exit(main())
